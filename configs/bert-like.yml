dataset:
  train_path: data/train.json
  dev_path: data/dev.json
  test_path: data/test1.json
  total_train_path: data/total_train.json

model:
  name: bert-base-chinese
  optimizer: AdamW
  criterion: cross_entropy
#  metric: f1-score
  lr_schedule: get_linear_schedule_with_warmup

solver:
  output_path: output/
  adversarial_training: none  # none means not use. fgm„ÄÅpgd and freelb.
  val_check_interval: 1.0
  seed: 0
  kfold: 5
  n_best_size: 5
  max_answer_length: 200
  cls_threshold: 0.7
  max_length: 256
  stride: 100
  batch_size: 8
  accumulate_grad_batches: 1
  precision: 32
  weight_decay: 0.01
  initial_lr: 1.0e-5
  linear_initial_lr: 1.0e-5
  gradient_clip_val: 0
  warmup_fraction: 0.1
  num_epochs: 1

